{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Common Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class APISettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(env_file='../.env', env_file_encoding='utf-8', extra='ignore')\n",
    "\n",
    "    OPENAI_API_KEY: str\n",
    "    ANTHROPIC_API_KEY: str\n",
    "    MISTRAL_API_KEY:str\n",
    "    \n",
    "    LANGCHAIN_API_KEY: str\n",
    "    LANGCHAIN_TRACING_V2: str = \"true\"\n",
    "\n",
    "api_settings = APISettings()\n",
    "for tuple in api_settings:\n",
    "    print(f\"{tuple[0]}:\\t\\t{tuple[1][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Spanish\"),\n",
    "    HumanMessage(content=\"How are you doing?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat_openai_model = ChatOpenAI(model=\"gpt-4\",openai_api_key=api_settings.OPENAI_API_KEY)\n",
    "\n",
    "chat_openai_model.invoke(messages).dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain_anthropic\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "anthropic_model = ChatAnthropic(model=\"claude-3-sonnet-20240229\",anthropic_api_key=api_settings.ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_model.invoke(messages).dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mistral AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_model = ChatMistralAI(model=\"mistral-large-latest\",mistral_api_key=api_settings.MISTRAL_API_KEY)\n",
    "mistral_result=mistral_model.invoke(messages)\n",
    "mistral_result.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.invoke(mistral_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = anthropic_model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Tagging Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r ../requirements.notebooks.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai\n",
    "%pip install --upgrade --quiet python-dotenv\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the API key is available\n",
    "import os\n",
    "assert 'OPENAI_API_KEY' in os.environ, 'Please set the OPENAI_API_KEY env var'\n",
    "print(f'API key is set. Length: {len(os.environ[\"OPENAI_API_KEY\"])}, starting with: {os.environ[\"OPENAI_API_KEY\"][:8]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\").with_structured_output(\n",
    "    Classification\n",
    ")\n",
    "\n",
    "tagging_chain = tagging_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "tagging_chain.invoke({\"input\": inp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcastic_sentences = [\n",
    "    \"Qué alegría, otra reunión que podría haber sido un correo electrónico.\",\n",
    "    \"I'm so glad it's Monday. I was getting tired of all that weekend freedom.\",\n",
    "    \"Wow, standing in line for hours is my absolute favorite pastime.\",\n",
    "    \"Toll, noch eine Baustelle auf meinem Arbeitsweg. Ich liebe Staus am Morgen.\",\n",
    "    \"Wunderbar, mein Nachbar übt wieder um Mitternacht Trompete. Wie melodisch.\",\n",
    "    \".יופי, אני אשב לי פה לבד בחושך\",\n",
    "    \"!בדיוק מה שהייתי צריך היום\"\n",
    "]\n",
    "for s in sarcastic_sentences:\n",
    "    print(tagging_chain.invoke({\"input\": s}).dict(),f\" {s[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationEx(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"alegre\", \"excited\", \"neutral\", \"indifferent\", \"triste\", \"sarcástico\", \"enojado\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"Castellano\", \"English\", \"Deutsch\", \"עברית\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ext = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\").with_structured_output(\n",
    "    ClassificationEx\n",
    ")\n",
    "tagging_chain_ex = tagging_prompt | llm_ext\n",
    "\n",
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "tagging_chain_ex.invoke({\"input\": inp})\n",
    "\n",
    "for s in sarcastic_sentences:\n",
    "    print(tagging_chain_ex.invoke({\"input\": s}).dict(),f\" {s[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
